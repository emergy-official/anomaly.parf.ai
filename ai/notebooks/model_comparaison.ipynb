{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparaison For Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Introduction\n",
    "- Before running the notebook\n",
    "- Config\n",
    "- Run the evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code used to run the evaluation on all models and all datasets so you can compare the results.\n",
    "The project output is as follow:\n",
    "- [stats_for_website.json](https://drive.google.com/file/d/1mBRRRhWLsV2pCC-GMst-9KQ65Owj3jXH/view?usp=sharing) - File used to display the stats on the dataset explorer\n",
    "\n",
    "\n",
    "- [benchmarks.json](https://drive.google.com/file/d/1cBk0Yd2smMMskUp4U7lPeS2lM2tFPapC/view?usp=sharing) - File used to display the benchmark on the dataset explorer\n",
    "\n",
    "\n",
    "- In the dataset, duplicate each pictures with it's inference results from efficientad, including the heatmpa. Each file has a `_result` in the filename. Used on the table in the dataset explorer. All the images on this have been reduced to 300x300. You can download the results.zip [here](https://drive.google.com/file/d/1nSSYSPowrj8FwpAAX5cLDZEQldFVf9Uk/view?usp=sharing).\n",
    "\n",
    "Here is the command used if you are interested: \n",
    "```sh\n",
    "find . -type f \\( -name \"*.jpg\" -o -name \"*.png\" \\) -exec sips -Z 300 {} \\;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the environement before running the notebook.\n",
    "\n",
    "Make sure you have run the notebooks `1_baseline`, `2_efficientad`, `3_fomoad` before running this!\n",
    "\n",
    "Run the following command in the terminal from the **`ai`** folder.\n",
    "\n",
    "```sh\n",
    "conda create -p envs/evaluate python=3.11.7 -y\n",
    "conda activate envs/evaluate\n",
    "\n",
    "pip install -r requirements/evaluate.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  # Import the sys module, required to access system-specific parameters and functions  \n",
    "sys.path.append('../code/')  # Add the '../code/' directory to the path that Python looks in for files to import  \n",
    "  \n",
    "from evaluate import * # Import all contents of the evaluate module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"dataset_path\": \"datasets\",\n",
    "    \"baseline\" : {\n",
    "        \"cookies_1\": \"../output/baseline/cookies_1\",\n",
    "        \"cookies_2\": \"../output/baseline/cookies_2\",\n",
    "        \"cookies_3\": \"../output/baseline/cookies_3\",\n",
    "    },\n",
    "    \"efficientad\" : {\n",
    "        \"cookies_1\": \"../output/efficientad/cookies_1\",\n",
    "        \"cookies_2\": \"../output/efficientad/cookies_2\",\n",
    "        \"cookies_3\": \"../output/efficientad/cookies_3\",\n",
    "    },\n",
    "    \"fomoad\" : { # Put both mac and linux\n",
    "        \"cookies_1\": \"../output/fomoad/cookies_1\",\n",
    "        \"cookies_1_threshold\": 3.7,\n",
    "        \"cookies_2\": \"../output/fomoad/cookies_2\",\n",
    "        \"cookies_2_threshold\": 5.2,\n",
    "        \"cookies_3\": \"../output/fomoad/cookies_3\",\n",
    "        \"cookies_3_threshold\": 5.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(subdataset):\n",
    "     torch.manual_seed(config[\"seed\"])\n",
    "     np.random.seed(config[\"seed\"])\n",
    "     random.seed(config[\"seed\"])\n",
    "\n",
    "     no_anomaly_paths = glob.glob(f\"{config['dataset_path']}/{subdataset}/no_anomaly/*.jpg\")  # adjust the pattern if needed\n",
    "\n",
    "     no_anomaly_train_paths, no_anomaly_test_paths = train_test_split(no_anomaly_paths, test_size=0.2, random_state=config[\"seed\"])\n",
    "     no_anomaly_train_paths,  no_anomaly_val_paths = train_test_split(no_anomaly_train_paths, test_size=0.1, random_state=config[\"seed\"])\n",
    "\n",
    "     anomaly_lvl_1_paths = glob.glob(f\"{config['dataset_path']}/{subdataset}/anomaly_lvl_1/*.jpg\")\n",
    "     anomaly_lvl_2_paths = glob.glob(f\"{config['dataset_path']}/{subdataset}/anomaly_lvl_2/*.jpg\")\n",
    "     anomaly_lvl_3_paths = glob.glob(f\"{config['dataset_path']}/{subdataset}/anomaly_lvl_3/*.jpg\")\n",
    "\n",
    "     anomaly_lvl_1_test_paths, anomaly_lvl_1_val_paths = train_test_split(anomaly_lvl_1_paths, test_size=0.2, random_state=config[\"seed\"])\n",
    "     anomaly_lvl_2_test_paths, anomaly_lvl_2_val_paths = train_test_split(anomaly_lvl_2_paths, test_size=0.2, random_state=config[\"seed\"])\n",
    "     anomaly_lvl_3_test_paths, anomaly_lvl_3_val_paths = train_test_split(anomaly_lvl_3_paths, test_size=0.2, random_state=config[\"seed\"])\n",
    "     \n",
    "     \n",
    "     no_anomaly_labels = [\"no_anomaly\"] * len(no_anomaly_test_paths)\n",
    "     no_anomaly_difficulty = [\"na\"] * len(no_anomaly_test_paths)\n",
    "\n",
    "     anomaly_1_labels = [\"anomaly\"] * len(anomaly_lvl_1_test_paths)\n",
    "     anomaly_1_difficulty = [\"easy\"] * len(anomaly_lvl_1_test_paths)\n",
    "\n",
    "     anomaly_2_labels = [\"anomaly\"] * len(anomaly_lvl_2_test_paths)\n",
    "     anomaly_2_difficulty = [\"medium\"] * len(anomaly_lvl_2_test_paths)\n",
    "\n",
    "     anomaly_3_labels = [\"anomaly\"] * len(anomaly_lvl_3_test_paths)\n",
    "     anomaly_3_difficulty = [\"hard\"] * len(anomaly_lvl_3_test_paths)\n",
    "\n",
    "     no_anomaly_df = pd.DataFrame({'filename': no_anomaly_test_paths, 'class': no_anomaly_labels, 'difficulty': no_anomaly_difficulty})  \n",
    "\n",
    "     \n",
    "     anomaly_1_df = pd.DataFrame({'filename': anomaly_lvl_1_test_paths, 'class': anomaly_1_labels, 'difficulty': anomaly_1_difficulty})  \n",
    "     anomaly_2_df = pd.DataFrame({'filename': anomaly_lvl_2_test_paths, 'class': anomaly_2_labels, 'difficulty': anomaly_2_difficulty})  \n",
    "     anomaly_3_df = pd.DataFrame({'filename': anomaly_lvl_3_test_paths, 'class': anomaly_3_labels, 'difficulty': anomaly_3_difficulty})\n",
    "\n",
    "     combined_df = pd.concat([no_anomaly_df, anomaly_1_df, anomaly_2_df, anomaly_3_df])\n",
    "     return combined_df.reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_baseline(dataset_name):\n",
    "    baseline_model = tf.keras.models.load_model(f'{config[\"baseline\"][dataset_name]}/local.keras')\n",
    "    edge_impulse_model_converted = ImageImpulseRunner(f'{config[\"baseline\"][dataset_name]}/ei.eim')\n",
    "    edge_impulse_model_converted.init()\n",
    "        \n",
    "    return baseline_model, edge_impulse_model_converted\n",
    "\n",
    "def evaluate_baseline(baseline_model, edge_impulse_model_converted, item):\n",
    "    cl, time, memory, score = inference_baseline(baseline_model, item[\"filename\"])\n",
    "    cl_ei, time_ei, memory_ei, score_ei = inference_baseline_ei(edge_impulse_model_converted, item[\"filename\"])\n",
    "    return cl, time, memory, score, cl_ei, time_ei, memory_ei, score_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_efficientad(dataset_name):\n",
    "    config_efficient_ad = {\n",
    "        \"seed\": 42,\n",
    "        \"on_gpu\": torch.cuda.is_available(),\n",
    "        \n",
    "        \"out_channels\": 384,\n",
    "        \"image_size\": 256,\n",
    "    }\n",
    "    \n",
    "    efficientad_models = torch.load(f'{config[\"efficientad\"][dataset_name]}/all_models.pth', map_location=torch.device('cpu'))\n",
    "    map_normalization = torch.load(f'{config[\"efficientad\"][dataset_name]}/map_normalization.pth', map_location=torch.device('cpu')) \n",
    "    \n",
    "    with open(f'{config[\"efficientad\"][dataset_name]}/best_threshold.pkl', 'rb') as file:  \n",
    "        best_threshold = pickle.load(file) \n",
    "     \n",
    "    efficientad = EfficientADInference(\n",
    "        config=config_efficient_ad,\n",
    "        models=efficientad_models,\n",
    "        map_normalization=map_normalization,\n",
    "        threshold=best_threshold,\n",
    "    )\n",
    "    \n",
    "    return efficientad\n",
    "\n",
    "def evaluate_efficientad(efficientad, item):\n",
    "    cl, time, memory, score = inference_efficientad(efficientad, item[\"filename\"])\n",
    "    return cl, time, memory, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fomoad(dataset_name):\n",
    "    edge_impulse_model_fomoad = ImageImpulseRunner(f'{config[\"fomoad\"][dataset_name]}/fomoad_runner-mac-x86_64.eim')\n",
    "    edge_impulse_model_fomoad.init()\n",
    "     \n",
    "    return edge_impulse_model_fomoad\n",
    "\n",
    "def evaluate_fomoad(edge_impulse_model_fomoad, item, threshold):\n",
    "    cl, time, memory, score = inference_fomoad_ei(edge_impulse_model_fomoad, item[\"filename\"], threshold)\n",
    "    return cl, time, memory, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_dataset(dataset_name):\n",
    "    print(f\"Evaluating {dataset_name}\")\n",
    "    \n",
    "    # Loading all model\n",
    "    baseline_model, ei_model_converted = load_baseline(dataset_name)\n",
    "    efficientad = load_efficientad(dataset_name)\n",
    "    ei_model_fomoad = load_fomoad(dataset_name)\n",
    "    \n",
    "    # Loading dataset\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    # Looping through the full dataset\n",
    "    for index, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        # Evaluate each model\n",
    "        cl_baseline, time_baseline, memory_baseline, score_baseline, cl_ei_baseline, time_ei_baseline, memory_ei_baseline, score_ei_baseline = evaluate_baseline(baseline_model, ei_model_converted, row)\n",
    "        \n",
    "        cl_efficientad, time_efficientad, memory_efficientad, score_efficientad = evaluate_efficientad(efficientad, row)\n",
    "        \n",
    "        cl_fomodad, time_fomoad, memory_fomoad, score_fomoad = evaluate_fomoad(ei_model_fomoad, row, config[\"fomoad\"][f\"{dataset_name}_threshold\"])\n",
    "        \n",
    "        # Update the dataframe to add the different scroes\n",
    "        dataset.at[index, 'cl_baseline'] = cl_baseline\n",
    "        dataset.at[index, 'time_baseline'] = time_baseline\n",
    "        dataset.at[index, 'memory_baseline'] = memory_baseline\n",
    "        dataset.at[index, 'score_baseline'] = score_baseline\n",
    "        \n",
    "        dataset.at[index, 'cl_ei_baseline'] = cl_ei_baseline\n",
    "        dataset.at[index, 'time_ei_baseline'] = time_ei_baseline\n",
    "        dataset.at[index, 'memory_ei_baseline'] = memory_ei_baseline\n",
    "        dataset.at[index, 'score_ei_baseline'] = score_ei_baseline\n",
    "        \n",
    "        dataset.at[index, 'cl_efficientad'] = cl_efficientad\n",
    "        dataset.at[index, 'time_efficientad'] = time_efficientad\n",
    "        dataset.at[index, 'memory_efficientad'] = memory_efficientad\n",
    "        dataset.at[index, 'score_efficientad'] = score_efficientad\n",
    "        \n",
    "        dataset.at[index, 'cl_fomodad'] = cl_fomodad\n",
    "        dataset.at[index, 'time_fomoad'] = time_fomoad\n",
    "        dataset.at[index, 'memory_fomoad'] = memory_fomoad\n",
    "        dataset.at[index, 'score_fomoad'] = score_fomoad\n",
    "        \n",
    "        save_path = row[\"filename\"].replace('.jpg', '_result.jpg')  \n",
    "        dataset.at[index, 'result_img_path'] = save_path\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating cookies_1\n",
      "- Setting seed to 42\n",
      "- OK - Setting seed to 42 (2.80 ms)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_1 = evaluate_one_dataset(\"cookies_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating cookies_2\n",
      "- Setting seed to 42\n",
      "- OK - Setting seed to 42 (1.18 ms)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = evaluate_one_dataset(\"cookies_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating cookies_3\n",
      "- Setting seed to 42\n",
      "- OK - Setting seed to 42 (1.07 ms)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_3 = evaluate_one_dataset(\"cookies_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cl_baseline</th>\n",
       "      <th>time_baseline</th>\n",
       "      <th>memory_baseline</th>\n",
       "      <th>score_baseline</th>\n",
       "      <th>cl_ei_baseline</th>\n",
       "      <th>time_ei_baseline</th>\n",
       "      <th>memory_ei_baseline</th>\n",
       "      <th>score_ei_baseline</th>\n",
       "      <th>cl_efficientad</th>\n",
       "      <th>time_efficientad</th>\n",
       "      <th>memory_efficientad</th>\n",
       "      <th>score_efficientad</th>\n",
       "      <th>cl_fomodad</th>\n",
       "      <th>time_fomoad</th>\n",
       "      <th>memory_fomoad</th>\n",
       "      <th>score_fomoad</th>\n",
       "      <th>result_img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134414.jpg</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>na</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>205.285788</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>75.807095</td>\n",
       "      <td>-368.0</td>\n",
       "      <td>0.571942</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>287.076235</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.028224</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>116.169930</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>3.977825</td>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134414_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134257.jpg</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>na</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>60.723066</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.747607</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>37.753105</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.736483</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>291.661978</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>35.536766</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>2.709480</td>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134257_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134101.jpg</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>na</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>37.206888</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.677503</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>36.581278</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.567319</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>321.985006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>37.643194</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>4.017349</td>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134101_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134452.jpg</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>na</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>41.023016</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.697850</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>30.738115</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.583880</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>290.608883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>35.781145</td>\n",
       "      <td>4016.0</td>\n",
       "      <td>4.191556</td>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134452_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134334.jpg</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>na</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>39.387941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642211</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>31.686783</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.502757</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>293.304920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>35.309076</td>\n",
       "      <td>4192.0</td>\n",
       "      <td>3.373817</td>\n",
       "      <td>datasets/cookies_3/no_anomaly/20240417_134334_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1406...</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>hard</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>40.112257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667141</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>31.785965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570048</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>306.662083</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>36.483049</td>\n",
       "      <td>-63008.0</td>\n",
       "      <td>5.378742</td>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1401...</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>hard</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>42.176008</td>\n",
       "      <td>-30576.0</td>\n",
       "      <td>0.566778</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>32.583952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825505</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>295.277834</td>\n",
       "      <td>-37664.0</td>\n",
       "      <td>0.061785</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>38.079023</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.081696</td>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1405...</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>hard</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>41.497946</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>37.628889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>292.452812</td>\n",
       "      <td>-21984.0</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>35.465240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.917777</td>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1405...</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>hard</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>37.263870</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.627439</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>32.335281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783686</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>301.133871</td>\n",
       "      <td>-27680.0</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>35.921335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.952106</td>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1406...</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>hard</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>99.685907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624606</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>33.328056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819309</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>295.104027</td>\n",
       "      <td>-2400.0</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>no_anomaly</td>\n",
       "      <td>36.050081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.260826</td>\n",
       "      <td>datasets/cookies_3/anomaly_lvl_3/20240417_1406...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename       class difficulty  \\\n",
       "0   datasets/cookies_3/no_anomaly/20240417_134414.jpg  no_anomaly         na   \n",
       "1   datasets/cookies_3/no_anomaly/20240417_134257.jpg  no_anomaly         na   \n",
       "2   datasets/cookies_3/no_anomaly/20240417_134101.jpg  no_anomaly         na   \n",
       "3   datasets/cookies_3/no_anomaly/20240417_134452.jpg  no_anomaly         na   \n",
       "4   datasets/cookies_3/no_anomaly/20240417_134334.jpg  no_anomaly         na   \n",
       "..                                                ...         ...        ...   \n",
       "95  datasets/cookies_3/anomaly_lvl_3/20240417_1406...     anomaly       hard   \n",
       "96  datasets/cookies_3/anomaly_lvl_3/20240417_1401...     anomaly       hard   \n",
       "97  datasets/cookies_3/anomaly_lvl_3/20240417_1405...     anomaly       hard   \n",
       "98  datasets/cookies_3/anomaly_lvl_3/20240417_1405...     anomaly       hard   \n",
       "99  datasets/cookies_3/anomaly_lvl_3/20240417_1406...     anomaly       hard   \n",
       "\n",
       "   cl_baseline  time_baseline  memory_baseline  score_baseline cl_ei_baseline  \\\n",
       "0   no_anomaly     205.285788           3760.0        0.629698     no_anomaly   \n",
       "1   no_anomaly      60.723066             48.0        0.747607     no_anomaly   \n",
       "2      anomaly      37.206888            208.0        0.677503     no_anomaly   \n",
       "3   no_anomaly      41.023016            112.0        0.697850     no_anomaly   \n",
       "4   no_anomaly      39.387941              0.0        0.642211        anomaly   \n",
       "..         ...            ...              ...             ...            ...   \n",
       "95  no_anomaly      40.112257              0.0        0.667141     no_anomaly   \n",
       "96     anomaly      42.176008         -30576.0        0.566778        anomaly   \n",
       "97     anomaly      41.497946           1072.0        0.652064        anomaly   \n",
       "98     anomaly      37.263870            288.0        0.627439        anomaly   \n",
       "99  no_anomaly      99.685907              0.0        0.624606     no_anomaly   \n",
       "\n",
       "    time_ei_baseline  memory_ei_baseline  score_ei_baseline cl_efficientad  \\\n",
       "0          75.807095              -368.0           0.571942     no_anomaly   \n",
       "1          37.753105               240.0           0.736483     no_anomaly   \n",
       "2          36.581278              1280.0           0.567319     no_anomaly   \n",
       "3          30.738115               208.0           0.583880     no_anomaly   \n",
       "4          31.686783               192.0           0.502757     no_anomaly   \n",
       "..               ...                 ...                ...            ...   \n",
       "95         31.785965                 0.0           0.570048        anomaly   \n",
       "96         32.583952                 0.0           0.825505        anomaly   \n",
       "97         37.628889                 0.0           0.857419        anomaly   \n",
       "98         32.335281                 0.0           0.783686        anomaly   \n",
       "99         33.328056                 0.0           0.819309        anomaly   \n",
       "\n",
       "    time_efficientad  memory_efficientad  score_efficientad  cl_fomodad  \\\n",
       "0         287.076235               160.0           0.028224  no_anomaly   \n",
       "1         291.661978                48.0           0.010483  no_anomaly   \n",
       "2         321.985006                 0.0           0.025547  no_anomaly   \n",
       "3         290.608883                 0.0           0.013774  no_anomaly   \n",
       "4         293.304920                 0.0           0.008547  no_anomaly   \n",
       "..               ...                 ...                ...         ...   \n",
       "95        306.662083              3152.0           0.075944     anomaly   \n",
       "96        295.277834            -37664.0           0.061785     anomaly   \n",
       "97        292.452812            -21984.0           0.062294     anomaly   \n",
       "98        301.133871            -27680.0           0.033368     anomaly   \n",
       "99        295.104027             -2400.0           0.126895  no_anomaly   \n",
       "\n",
       "    time_fomoad  memory_fomoad  score_fomoad  \\\n",
       "0    116.169930         3072.0      3.977825   \n",
       "1     35.536766         3200.0      2.709480   \n",
       "2     37.643194         3168.0      4.017349   \n",
       "3     35.781145         4016.0      4.191556   \n",
       "4     35.309076         4192.0      3.373817   \n",
       "..          ...            ...           ...   \n",
       "95    36.483049       -63008.0      5.378742   \n",
       "96    38.079023           16.0      8.081696   \n",
       "97    35.465240            0.0      6.917777   \n",
       "98    35.921335            0.0     12.952106   \n",
       "99    36.050081            0.0      4.260826   \n",
       "\n",
       "                                      result_img_path  \n",
       "0   datasets/cookies_3/no_anomaly/20240417_134414_...  \n",
       "1   datasets/cookies_3/no_anomaly/20240417_134257_...  \n",
       "2   datasets/cookies_3/no_anomaly/20240417_134101_...  \n",
       "3   datasets/cookies_3/no_anomaly/20240417_134452_...  \n",
       "4   datasets/cookies_3/no_anomaly/20240417_134334_...  \n",
       "..                                                ...  \n",
       "95  datasets/cookies_3/anomaly_lvl_3/20240417_1406...  \n",
       "96  datasets/cookies_3/anomaly_lvl_3/20240417_1401...  \n",
       "97  datasets/cookies_3/anomaly_lvl_3/20240417_1405...  \n",
       "98  datasets/cookies_3/anomaly_lvl_3/20240417_1405...  \n",
       "99  datasets/cookies_3/anomaly_lvl_3/20240417_1406...  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/0z24g8110_n09vlvhxmrh0_w0000gp/T/ipykernel_94509/1648641828.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  benchmarks = pd.concat([benchmarks, results_dataset1, results_dataset2, results_dataset3], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def get_score(dataset, name):  \n",
    "    row = [name]  \n",
    "    \n",
    "    # For Baseline  \n",
    "    f1_all_baseline = f1_score(dataset['class'], dataset['cl_baseline'], pos_label='anomaly')  \n",
    "    \n",
    "    f1_all_baseline_na = f1_score(dataset[dataset[\"difficulty\"] == \"na\"]['class'], dataset[dataset[\"difficulty\"] == \"na\"]['cl_baseline'], pos_label='no_anomaly')  \n",
    "    f1_all_baseline_lvl1 = f1_score(dataset[dataset[\"difficulty\"] == \"easy\"]['class'], dataset[dataset[\"difficulty\"] == \"easy\"]['cl_baseline'], pos_label='anomaly')  \n",
    "    f1_all_baseline_lvl2 = f1_score(dataset[dataset[\"difficulty\"] == \"medium\"]['class'], dataset[dataset[\"difficulty\"] == \"medium\"]['cl_baseline'], pos_label='anomaly')  \n",
    "    f1_all_baseline_lvl3 = f1_score(dataset[dataset[\"difficulty\"] == \"hard\"]['class'], dataset[dataset[\"difficulty\"] == \"hard\"]['cl_baseline'], pos_label='anomaly')  \n",
    "    row.extend([name, f1_all_baseline, f1_all_baseline_na, f1_all_baseline_lvl1, f1_all_baseline_lvl2, f1_all_baseline_lvl3,  \n",
    "                dataset['time_baseline'].mean(), dataset['memory_baseline'].mean()])  \n",
    "    # For Baseline EI  \n",
    "    f1_all_baseline_ei = f1_score(dataset['class'], dataset['cl_ei_baseline'], pos_label='anomaly')  \n",
    "    f1_all_baseline_ei_na = f1_score(dataset[dataset[\"difficulty\"] == \"na\"]['class'], dataset[dataset[\"difficulty\"] == \"na\"]['cl_ei_baseline'], pos_label='no_anomaly')  \n",
    "    f1_all_baseline_ei_lvl1 = f1_score(dataset[dataset[\"difficulty\"] == \"easy\"]['class'], dataset[dataset[\"difficulty\"] == \"easy\"]['cl_ei_baseline'], pos_label='anomaly')  \n",
    "    f1_all_baseline_ei_lvl2 = f1_score(dataset[dataset[\"difficulty\"] == \"medium\"]['class'], dataset[dataset[\"difficulty\"] == \"medium\"]['cl_ei_baseline'], pos_label='anomaly')  \n",
    "    f1_all_baseline_ei_lvl3 = f1_score(dataset[dataset[\"difficulty\"] == \"hard\"]['class'], dataset[dataset[\"difficulty\"] == \"hard\"]['cl_ei_baseline'], pos_label='anomaly')  \n",
    "    row.extend([name, f1_all_baseline_ei, f1_all_baseline_ei_na, f1_all_baseline_ei_lvl1, f1_all_baseline_ei_lvl2, f1_all_baseline_ei_lvl3,  \n",
    "                dataset['time_ei_baseline'].mean(), dataset['memory_ei_baseline'].mean()])  \n",
    "  \n",
    "    # For EfficientAD  \n",
    "    f1_all_efficientad = f1_score(dataset['class'], dataset['cl_efficientad'], pos_label='anomaly')  \n",
    "    f1_all_efficientad_na = f1_score(dataset[dataset[\"difficulty\"] == \"na\"]['class'], dataset[dataset[\"difficulty\"] == \"na\"]['cl_efficientad'], pos_label='no_anomaly')  \n",
    "    f1_all_efficientad_lvl1 = f1_score(dataset[dataset[\"difficulty\"] == \"easy\"]['class'], dataset[dataset[\"difficulty\"] == \"easy\"]['cl_efficientad'], pos_label='anomaly')  \n",
    "    f1_all_efficientad_lvl2 = f1_score(dataset[dataset[\"difficulty\"] == \"medium\"]['class'], dataset[dataset[\"difficulty\"] == \"medium\"]['cl_efficientad'], pos_label='anomaly')  \n",
    "    f1_all_efficientad_lvl3 = f1_score(dataset[dataset[\"difficulty\"] == \"hard\"]['class'], dataset[dataset[\"difficulty\"] == \"hard\"]['cl_efficientad'], pos_label='anomaly')  \n",
    "    row.extend([name, f1_all_efficientad, f1_all_efficientad_na, f1_all_efficientad_lvl1, f1_all_efficientad_lvl2, f1_all_efficientad_lvl3,  \n",
    "                dataset['time_efficientad'].mean(), dataset['memory_efficientad'].mean()])  \n",
    "  \n",
    "    # For FOMOAD  \n",
    "    f1_all_fomoad = f1_score(dataset['class'], dataset['cl_fomodad'], pos_label='anomaly')  \n",
    "    f1_all_fomoad_na = f1_score(dataset[dataset[\"difficulty\"] == \"na\"]['class'], dataset[dataset[\"difficulty\"] == \"na\"]['cl_fomodad'], pos_label='no_anomaly')  \n",
    "    f1_all_fomoad_lvl1 = f1_score(dataset[dataset[\"difficulty\"] == \"easy\"]['class'], dataset[dataset[\"difficulty\"] == \"easy\"]['cl_fomodad'], pos_label='anomaly')  \n",
    "    f1_all_fomoad_lvl2 = f1_score(dataset[dataset[\"difficulty\"] == \"medium\"]['class'], dataset[dataset[\"difficulty\"] == \"medium\"]['cl_fomodad'], pos_label='anomaly')  \n",
    "    f1_all_fomoad_lvl3 = f1_score(dataset[dataset[\"difficulty\"] == \"hard\"]['class'], dataset[dataset[\"difficulty\"] == \"hard\"]['cl_fomodad'], pos_label='anomaly')  \n",
    "    row.extend([name, f1_all_fomoad, f1_all_fomoad_na, f1_all_fomoad_lvl1, f1_all_fomoad_lvl2, f1_all_fomoad_lvl3,  \n",
    "                dataset['time_fomoad'].mean(), dataset['memory_fomoad'].mean()])  \n",
    "  \n",
    "    return row\n",
    "\n",
    "benchmarks = pd.DataFrame(columns=[\"Dataset\", 'Baseline Dataset', 'Baseline F1 TEST', 'Baseline F1 NO ANOMALY TEST', 'Baseline F1 EASY TEST', 'Baseline F1 MEDIUM TEST', 'Baseline F1 HARD TEST', 'Baseline Time (ms)', 'Baseline RAM (KB)',  \n",
    "                                   'Baseline EI Dataset', 'Baseline EI F1 TEST', 'Baseline EI F1 NO ANOMALY TEST', 'Baseline EI F1 EASY TEST', 'Baseline EI F1 MEDIUM TEST', 'Baseline EI F1 HARD TEST', 'Baseline EI Time (ms)', 'Baseline EI RAM (KB)',  \n",
    "                                   'EfficientAD Dataset', 'EfficientAD F1 TEST', 'EfficientAD F1 NO ANOMALY TEST', 'EfficientAD F1 EASY TEST', 'EfficientAD F1 MEDIUM TEST', 'EfficientAD F1 HARD TEST', 'EfficientAD Time (ms)', 'EfficientAD RAM (KB)',  \n",
    "                                   'FOMOAD Dataset', 'FOMOAD F1 TEST', 'FOMOAD F1 NO ANOMALY TEST', 'FOMOAD F1 EASY TEST', 'FOMOAD F1 MEDIUM TEST', 'FOMOAD F1 HARD TEST', 'FOMOAD Time (ms)', 'FOMOAD RAM (KB)'])  \n",
    "  \n",
    "# Assuming dataset1, dataset2, dataset3 are your actual datasets  \n",
    "results_dataset1 = pd.DataFrame([get_score(dataset_1, \"cookies_1\")], columns=benchmarks.columns)  \n",
    "results_dataset2 = pd.DataFrame([get_score(dataset_2, \"cookies_2\")], columns=benchmarks.columns)  \n",
    "results_dataset3 = pd.DataFrame([get_score(dataset_3, \"cookies_3\")], columns=benchmarks.columns)  \n",
    "\n",
    "def dataframe_to_dict(df):  \n",
    "    return df.to_dict(orient='records')[0]  \n",
    "\n",
    "results = {  \n",
    "    \"cookies_1\": dataframe_to_dict(results_dataset1),  \n",
    "    \"cookies_2\": dataframe_to_dict(results_dataset2),  \n",
    "    \"cookies_3\": dataframe_to_dict(results_dataset3)  \n",
    "}\n",
    "\n",
    "benchmarks = pd.concat([benchmarks, results_dataset1, results_dataset2, results_dataset3], ignore_index=True)\n",
    "import json\n",
    "with open('../output/benchmarks.json', 'w') as outfile:  \n",
    "    outfile.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Baseline Dataset</th>\n",
       "      <th>Baseline F1 TEST</th>\n",
       "      <th>Baseline F1 NO ANOMALY TEST</th>\n",
       "      <th>Baseline F1 EASY TEST</th>\n",
       "      <th>Baseline F1 MEDIUM TEST</th>\n",
       "      <th>Baseline F1 HARD TEST</th>\n",
       "      <th>Baseline Time (ms)</th>\n",
       "      <th>Baseline RAM (KB)</th>\n",
       "      <th>Baseline EI Dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>EfficientAD Time (ms)</th>\n",
       "      <th>EfficientAD RAM (KB)</th>\n",
       "      <th>FOMOAD Dataset</th>\n",
       "      <th>FOMOAD F1 TEST</th>\n",
       "      <th>FOMOAD F1 NO ANOMAL TEST</th>\n",
       "      <th>FOMOAD F1 EASY TEST</th>\n",
       "      <th>FOMOAD F1 MEDIUM TEST</th>\n",
       "      <th>FOMOAD F1 HARD TEST</th>\n",
       "      <th>FOMOAD Time (ms)</th>\n",
       "      <th>FOMOAD RAM (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies_1</td>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>39.690981</td>\n",
       "      <td>436.64</td>\n",
       "      <td>cookies_1</td>\n",
       "      <td>...</td>\n",
       "      <td>299.973309</td>\n",
       "      <td>9296.64</td>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>35.132482</td>\n",
       "      <td>2337.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Baseline Dataset  Baseline F1 TEST  Baseline F1 NO ANOMALY TEST  \\\n",
       "0  cookies_1        cookies_1          0.865248                          1.0   \n",
       "\n",
       "   Baseline F1 EASY TEST  Baseline F1 MEDIUM TEST  Baseline F1 HARD TEST  \\\n",
       "0                    1.0                      1.0               0.095238   \n",
       "\n",
       "   Baseline Time (ms)  Baseline RAM (KB) Baseline EI Dataset  ...  \\\n",
       "0           39.690981             436.64           cookies_1  ...   \n",
       "\n",
       "   EfficientAD Time (ms)  EfficientAD RAM (KB)  FOMOAD Dataset  \\\n",
       "0             299.973309               9296.64       cookies_1   \n",
       "\n",
       "   FOMOAD F1 TEST  FOMOAD F1 NO ANOMAL TEST  FOMOAD F1 EASY TEST  \\\n",
       "0        0.954248                       1.0                  1.0   \n",
       "\n",
       "   FOMOAD F1 MEDIUM TEST FOMOAD F1 HARD TEST  FOMOAD Time (ms)  \\\n",
       "0                    1.0            0.787879         35.132482   \n",
       "\n",
       "   FOMOAD RAM (KB)  \n",
       "0           2337.6  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>F1 TEST</th>\n",
       "      <th>F1 NO ANOMALY</th>\n",
       "      <th>F1 EASY</th>\n",
       "      <th>F1 MEDIUM</th>\n",
       "      <th>F1 HARD</th>\n",
       "      <th>Time (ms)</th>\n",
       "      <th>RAM (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>39.690981</td>\n",
       "      <td>436.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookies_2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>43.644302</td>\n",
       "      <td>125.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookies_3</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>42.710402</td>\n",
       "      <td>-192.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset   F1 TEST  F1 NO ANOMALY  F1 EASY  F1 MEDIUM   F1 HARD  \\\n",
       "0  cookies_1  0.865248       1.000000      1.0        1.0  0.095238   \n",
       "1  cookies_2  0.888889       1.000000      1.0        1.0  0.333333   \n",
       "2  cookies_3  0.917197       0.857143      1.0        1.0  0.750000   \n",
       "\n",
       "   Time (ms)  RAM (KB)  \n",
       "0  39.690981    436.64  \n",
       "1  43.644302    125.12  \n",
       "2  42.710402   -192.32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline EI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>F1 TEST</th>\n",
       "      <th>F1 NO ANOMALY</th>\n",
       "      <th>F1 EASY</th>\n",
       "      <th>F1 MEDIUM</th>\n",
       "      <th>F1 HARD</th>\n",
       "      <th>Time (ms)</th>\n",
       "      <th>RAM (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>31.956229</td>\n",
       "      <td>476.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookies_2</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>33.593299</td>\n",
       "      <td>17.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookies_3</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>33.523099</td>\n",
       "      <td>244.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset   F1 TEST  F1 NO ANOMALY  F1 EASY  F1 MEDIUM   F1 HARD  \\\n",
       "0  cookies_1  0.875000       0.974359      1.0        1.0  0.260870   \n",
       "1  cookies_2  0.954248       1.000000      1.0        1.0  0.787879   \n",
       "2  cookies_3  0.941935       0.947368      1.0        1.0  0.787879   \n",
       "\n",
       "   Time (ms)  RAM (KB)  \n",
       "0  31.956229    476.80  \n",
       "1  33.593299     17.92  \n",
       "2  33.523099    244.48  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientAD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>F1 TEST</th>\n",
       "      <th>F1 NO ANOMALY</th>\n",
       "      <th>F1 EASY</th>\n",
       "      <th>F1 MEDIUM</th>\n",
       "      <th>F1 HARD</th>\n",
       "      <th>Time (ms)</th>\n",
       "      <th>RAM (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>299.973309</td>\n",
       "      <td>9296.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookies_2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>318.657351</td>\n",
       "      <td>2638.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookies_3</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>305.910184</td>\n",
       "      <td>2326.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset   F1 TEST  F1 NO ANOMALY  F1 EASY  F1 MEDIUM   F1 HARD  \\\n",
       "0  cookies_1  0.904110            1.0      1.0   1.000000  0.461538   \n",
       "1  cookies_2  0.888889            1.0      1.0   0.918919  0.518519   \n",
       "2  cookies_3  0.993711            1.0      1.0   1.000000  0.974359   \n",
       "\n",
       "    Time (ms)  RAM (KB)  \n",
       "0  299.973309   9296.64  \n",
       "1  318.657351   2638.08  \n",
       "2  305.910184   2326.72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOMO AD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>F1 TEST</th>\n",
       "      <th>F1 NO ANOMALY</th>\n",
       "      <th>F1 EASY</th>\n",
       "      <th>F1 MEDIUM</th>\n",
       "      <th>F1 HARD</th>\n",
       "      <th>Time (ms)</th>\n",
       "      <th>RAM (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies_1</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>35.132482</td>\n",
       "      <td>2337.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookies_2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.245327</td>\n",
       "      <td>129.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookies_3</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>38.416507</td>\n",
       "      <td>956.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset   F1 TEST  F1 NO ANOMALY  F1 EASY  F1 MEDIUM   F1 HARD  \\\n",
       "0  cookies_1  0.954248            1.0      1.0        1.0  0.787879   \n",
       "1  cookies_2  1.000000            1.0      1.0        1.0  1.000000   \n",
       "2  cookies_3  0.993711            1.0      1.0        1.0  0.974359   \n",
       "\n",
       "   Time (ms)  RAM (KB)  \n",
       "0  35.132482   2337.60  \n",
       "1  38.245327    129.12  \n",
       "2  38.416507    956.32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_columns = pd.MultiIndex.from_tuples([  \n",
    "    ('', 'Dataset'),                                # Common dataset column  \n",
    "    ('Baseline', 'Dataset'),  \n",
    "    ('Baseline', 'F1 TEST'), ('Baseline', 'F1 NO ANOMALY'), ('Baseline', 'F1 EASY'), ('Baseline', 'F1 MEDIUM'), ('Baseline', 'F1 HARD'), ('Baseline', 'Time (ms)'), ('Baseline', 'RAM (KB)'),  \n",
    "    ('Baseline EI', 'Dataset'),  \n",
    "    ('Baseline EI', 'F1 TEST'), ('Baseline EI', 'F1 NO ANOMALY'), ('Baseline EI', 'F1 EASY'), ('Baseline EI', 'F1 MEDIUM'), ('Baseline EI', 'F1 HARD'), ('Baseline EI', 'Time (ms)'), ('Baseline EI', 'RAM (KB)'),  \n",
    "    ('EfficientAD', 'Dataset'),  \n",
    "    ('EfficientAD', 'F1 TEST'), ('EfficientAD', 'F1 NO ANOMALY'), ('EfficientAD', 'F1 EASY'), ('EfficientAD', 'F1 MEDIUM'), ('EfficientAD', 'F1 HARD'), ('EfficientAD', 'Time (ms)'), ('EfficientAD', 'RAM (KB)'),  \n",
    "    ('FOMOAD', 'Dataset'),  \n",
    "    ('FOMOAD', 'F1 TEST'), ('FOMOAD', 'F1 NO ANOMALY'), ('FOMOAD', 'F1 EASY'), ('FOMOAD', 'F1 MEDIUM'), ('FOMOAD', 'F1 HARD'), ('FOMOAD', 'Time (ms)'), ('FOMOAD', 'RAM (KB)')  \n",
    "])  \n",
    "benchmarks.columns = new_columns  \n",
    "\n",
    "# Show styled DataFrame  \n",
    "print(\"BASELINE\")\n",
    "display(benchmarks.loc[:, 'Baseline'])\n",
    "print(\"Baseline EI\")\n",
    "display(benchmarks.loc[:, 'Baseline EI'])  \n",
    "print(\"EfficientAD\")\n",
    "display(benchmarks.loc[:, 'EfficientAD'])\n",
    "print(\"FOMO AD\")\n",
    "display(benchmarks.loc[:, 'FOMOAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks.to_csv('../output/benchmarks.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_json(df):\n",
    "    # Transform DataFrame to the specified JSON structure  \n",
    "    transformed_data = {  \n",
    "        'baseline': df[['filename', 'class', 'difficulty', 'cl_baseline', 'score_baseline', 'time_baseline']].rename(columns={  \n",
    "            'filename': 'i',  \n",
    "            'class': 'c',  \n",
    "            'difficulty': 'd',  \n",
    "            'cl_baseline': 'cl',  \n",
    "            'score_baseline': 's',  \n",
    "            'time_baseline': 't'  \n",
    "        }).to_dict(orient='records'),  \n",
    "        'baseline-ei': df[['filename', 'class', 'difficulty', 'cl_ei_baseline', 'score_ei_baseline', 'time_ei_baseline']].rename(columns={  \n",
    "             'filename': 'i',  \n",
    "            'class': 'c',  \n",
    "            'difficulty': 'd',  \n",
    "            'cl_ei_baseline': 'cl',  \n",
    "            'score_ei_baseline': 's',  \n",
    "            'time_ei_baseline': 't'  \n",
    "        }).to_dict(orient='records'),  \n",
    "        'efficientad': df[['filename', 'class', 'difficulty', 'cl_efficientad', 'score_efficientad', 'time_efficientad', 'result_img_path']].rename(columns={  \n",
    "            'filename': 'i',  \n",
    "            'class': 'c',  \n",
    "            'difficulty': 'd',  \n",
    "            'cl_efficientad': 'cl',  \n",
    "            'score_efficientad': 's',  \n",
    "            'time_efficientad': 't',  \n",
    "            'result_img_path': 'r'  \n",
    "        }).to_dict(orient='records'),  \n",
    "        'fomoad': df[['filename', 'class', 'difficulty', 'cl_fomodad', 'score_fomoad', 'time_fomoad']].rename(columns={  \n",
    "            'filename': 'i',  \n",
    "            'class': 'c',  \n",
    "            'difficulty': 'd',  \n",
    "            'cl_fomodad': 'cl',  \n",
    "            'score_fomoad': 's',  \n",
    "            'time_fomoad': 't'  \n",
    "        }).to_dict(orient='records')\n",
    "    }\n",
    "    \n",
    "    return  transformed_data\n",
    "\n",
    "t1 =  dataframe_to_json(dataset_1)\n",
    "t2 =  dataframe_to_json(dataset_2)\n",
    "t3 =  dataframe_to_json(dataset_3)\n",
    "\n",
    "stats_for_website = {\n",
    "    \"cookies_1\": t1,\n",
    "    \"cookies_2\": t2,\n",
    "    \"cookies_3\": t3,\n",
    "}\n",
    "import json  \n",
    "with open('../output/stats_for_website.json', 'w') as outfile:  \n",
    "    json.dump(stats_for_website, outfile)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
